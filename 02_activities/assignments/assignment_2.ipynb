{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this assigment, we will work with the *Adult* data set. Please download the data from the [UCI Machine Learning Repository](https://archive.ics.uci.edu/dataset/2/adult). Extract the data files into the subdirectory: `../05_src/data/adult/` (relative to `./05_src/`)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the data\n",
    "\n",
    "Assuming that the files `adult.data` and `adult.test` are in `../05_src/data/adult/`, then you can use the code below to load them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       age          workclass  fnlwgt    education  education-num  \\\n",
      "0       39          State-gov   77516    Bachelors             13   \n",
      "1       50   Self-emp-not-inc   83311    Bachelors             13   \n",
      "2       38            Private  215646      HS-grad              9   \n",
      "3       53            Private  234721         11th              7   \n",
      "4       28            Private  338409    Bachelors             13   \n",
      "...    ...                ...     ...          ...            ...   \n",
      "32556   27            Private  257302   Assoc-acdm             12   \n",
      "32557   40            Private  154374      HS-grad              9   \n",
      "32558   58            Private  151910      HS-grad              9   \n",
      "32559   22            Private  201490      HS-grad              9   \n",
      "32560   52       Self-emp-inc  287927      HS-grad              9   \n",
      "\n",
      "            marital-status          occupation    relationship    race  \\\n",
      "0            Never-married        Adm-clerical   Not-in-family   White   \n",
      "1       Married-civ-spouse     Exec-managerial         Husband   White   \n",
      "2                 Divorced   Handlers-cleaners   Not-in-family   White   \n",
      "3       Married-civ-spouse   Handlers-cleaners         Husband   Black   \n",
      "4       Married-civ-spouse      Prof-specialty            Wife   Black   \n",
      "...                    ...                 ...             ...     ...   \n",
      "32556   Married-civ-spouse        Tech-support            Wife   White   \n",
      "32557   Married-civ-spouse   Machine-op-inspct         Husband   White   \n",
      "32558              Widowed        Adm-clerical       Unmarried   White   \n",
      "32559        Never-married        Adm-clerical       Own-child   White   \n",
      "32560   Married-civ-spouse     Exec-managerial            Wife   White   \n",
      "\n",
      "           sex  capital-gain  capital-loss  hours-per-week  native-country  \\\n",
      "0         Male          2174             0              40   United-States   \n",
      "1         Male             0             0              13   United-States   \n",
      "2         Male             0             0              40   United-States   \n",
      "3         Male             0             0              40   United-States   \n",
      "4       Female             0             0              40            Cuba   \n",
      "...        ...           ...           ...             ...             ...   \n",
      "32556   Female             0             0              38   United-States   \n",
      "32557     Male             0             0              40   United-States   \n",
      "32558   Female             0             0              40   United-States   \n",
      "32559     Male             0             0              20   United-States   \n",
      "32560   Female         15024             0              40   United-States   \n",
      "\n",
      "       income  \n",
      "0           0  \n",
      "1           0  \n",
      "2           0  \n",
      "3           0  \n",
      "4           0  \n",
      "...       ...  \n",
      "32556       0  \n",
      "32557       1  \n",
      "32558       0  \n",
      "32559       0  \n",
      "32560       1  \n",
      "\n",
      "[32561 rows x 15 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "columns = [\n",
    "    'age', 'workclass', 'fnlwgt', 'education', 'education-num', 'marital-status',\n",
    "    'occupation', 'relationship', 'race', 'sex', 'capital-gain', 'capital-loss', 'hours-per-week',\n",
    "    'native-country', 'income'\n",
    "]\n",
    "adult_dt = (pd.read_csv('../../05_src/data/adult/adult.data', header = None, names = columns)\n",
    "              .assign(income = lambda x: (x.income.str.strip() == '>50K')*1))\n",
    "\n",
    "print(adult_dt)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get X and Y\n",
    "\n",
    "Create the features data frame and target data:\n",
    "\n",
    "+ Create a dataframe `X` that holds the features (all columns that are not `income`).\n",
    "+ Create a dataframe `Y` that holds the target data (`income`).\n",
    "+ From `X` and `Y`, obtain the training and testing data sets:\n",
    "\n",
    "    - Use a train-test split of 70-30%. \n",
    "    - Set the random state of the splitting function to 42."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random States\n",
    "\n",
    "Please comment: \n",
    "\n",
    "+ What is the [random state](https://scikit-learn.org/stable/glossary.html#term-random_state) of the [splitting function](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html)? \n",
    "\n",
    "\n",
    "+ Why is it [useful](https://en.wikipedia.org/wiki/Reproducibility)?\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*(Comment here.)*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing\n",
    "\n",
    "Create a [Column Transformer](https://scikit-learn.org/stable/modules/generated/sklearn.compose.ColumnTransformer.html) that treats the features as follows:\n",
    "\n",
    "- Numerical variables\n",
    "\n",
    "    * Apply [KNN-based imputation for completing missing values](https://scikit-learn.org/stable/modules/generated/sklearn.impute.KNNImputer.html):\n",
    "        \n",
    "        + Consider the 7 nearest neighbours.\n",
    "        + Weight each neighbour by the inverse of its distance, causing closer neigbours to have more influence than more distant ones.\n",
    "    * [Scale features using statistics that are robust to outliers](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.RobustScaler.html#sklearn.preprocessing.RobustScaler).\n",
    "\n",
    "- Categorical variables: \n",
    "    \n",
    "    * Apply a [simple imputation strategy](https://scikit-learn.org/stable/modules/generated/sklearn.impute.SimpleImputer.html#sklearn.impute.SimpleImputer):\n",
    "\n",
    "        + Use the most frequent value to complete missing values, also called the *mode*.\n",
    "\n",
    "    * Apply [one-hot encoding](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.OneHotEncoder.html):\n",
    "        \n",
    "        + Handle unknown labels if they exist.\n",
    "        + Drop one column for binary variables.\n",
    "    \n",
    "    \n",
    "The column transformer should look like this:\n",
    "\n",
    "![](./images/assignment_2__column_transformer.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transformed X_train shape: (22792, 100)\n",
      "Transformed X_test shape: (9769, 100)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.impute import KNNImputer, SimpleImputer\n",
    "from sklearn.preprocessing import RobustScaler, OneHotEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Define the numerical and categorical features\n",
    "numerical_features = [\n",
    "    'age', 'fnlwgt', 'education-num', 'capital-gain', 'capital-loss', 'hours-per-week'\n",
    "]\n",
    "categorical_features = [\n",
    "    'workclass', 'education', 'marital-status', 'occupation', 'relationship', 'race', 'sex', 'native-country'\n",
    "]\n",
    "\n",
    "# Create a pipeline for preprocessing the numerical features\n",
    "numerical_pipeline = Pipeline(steps=[\n",
    "    ('imputer', KNNImputer(n_neighbors=7, weights='distance')),  # KNN imputation\n",
    "    ('scaler', RobustScaler())  # Robust scaling\n",
    "])\n",
    "\n",
    "# Create a pipeline for preprocessing the categorical features\n",
    "categorical_pipeline = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),  # Impute using the most frequent value (mode)\n",
    "    ('encoder', OneHotEncoder(handle_unknown='ignore', drop='first'))  # One-hot encoding with dropping binary variable column\n",
    "])\n",
    "\n",
    "# Create the column transformer\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numerical_pipeline, numerical_features),  # Process numerical features\n",
    "        ('cat', categorical_pipeline, categorical_features)  # Process categorical features\n",
    "    ])\n",
    "\n",
    "# Example: Fit and transform the training data (X_train)\n",
    "X_train_transformed = preprocessor.fit_transform(X_train)\n",
    "\n",
    "# Example: Transform the test data (X_test)\n",
    "X_test_transformed = preprocessor.transform(X_test)\n",
    "\n",
    "# Optionally, you can print the shapes of the transformed data to check\n",
    "print(\"Transformed X_train shape:\", X_train_transformed.shape)\n",
    "print(\"Transformed X_test shape:\", X_test_transformed.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Pipeline\n",
    "\n",
    "Create a [model pipeline](https://scikit-learn.org/stable/modules/generated/sklearn.pipeline.Pipeline.html): \n",
    "\n",
    "+ Add a step labelled `preprocessing` and assign the Column Transformer from the previous section.\n",
    "+ Add a step labelled `classifier` and assign a [`RandomForestClassifier()`](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html) to it.\n",
    "\n",
    "The pipeline looks like this:\n",
    "\n",
    "![](./images/assignment_2__pipeline.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8555635172484389\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.93      0.91      7455\n",
      "           1       0.73      0.63      0.67      2314\n",
      "\n",
      "    accuracy                           0.86      9769\n",
      "   macro avg       0.81      0.78      0.79      9769\n",
      "weighted avg       0.85      0.86      0.85      9769\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[6907  548]\n",
      " [ 863 1451]]\n"
     ]
    }
   ],
   "source": [
    "# Create the pipeline\n",
    "model_pipeline = Pipeline(steps=[\n",
    "    ('preprocessing', preprocessor),  # Apply the preprocessing step from the previous section\n",
    "    ('classifier', RandomForestClassifier(random_state=42))  # Add a RandomForestClassifier as the classifier\n",
    "])\n",
    "\n",
    "# Fit the model on the training data\n",
    "model_pipeline.fit(X_train, Y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = model_pipeline.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "\n",
    "# Print accuracy\n",
    "print(f\"Accuracy: {accuracy_score(Y_test, y_pred)}\")\n",
    "\n",
    "# Print classification report\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(Y_test, y_pred))\n",
    "\n",
    "# Print confusion matrix\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(confusion_matrix(Y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cross-Validation\n",
    "\n",
    "Evaluate the model pipeline using [`cross_validate()`](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.cross_validate.html):\n",
    "\n",
    "+ Measure the following [preformance metrics](https://scikit-learn.org/stable/modules/model_evaluation.html#common-cases-predefined-values): negative log loss, ROC AUC, accuracy, and balanced accuracy.\n",
    "+ Report the training and validation results. \n",
    "+ Use five folds.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/envs/dsi_participant/lib/python3.9/site-packages/sklearn/preprocessing/_encoders.py:242: UserWarning: Found unknown categories in columns [7] during transform. These unknown categories will be encoded as all zeros\n",
      "  warnings.warn(\n",
      "/opt/miniconda3/envs/dsi_participant/lib/python3.9/site-packages/sklearn/preprocessing/_encoders.py:242: UserWarning: Found unknown categories in columns [7] during transform. These unknown categories will be encoded as all zeros\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training results:\n",
      "Mean Negative Log Loss: -0.0803\n",
      "Mean ROC AUC: 1.0000\n",
      "Mean Accuracy: 1.0000\n",
      "Mean Balanced Accuracy: 1.0000\n",
      "\n",
      "Validation results:\n",
      "Mean Negative Log Loss: -0.3698\n",
      "Mean ROC AUC: 0.9031\n",
      "Mean Accuracy: 0.8548\n",
      "Mean Balanced Accuracy: 0.7753\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.metrics import make_scorer, log_loss, roc_auc_score, accuracy_score, balanced_accuracy_score\n",
    "\n",
    "# Define the scoring metrics for cross-validation\n",
    "scoring = {\n",
    "    'neg_log_loss': 'neg_log_loss',\n",
    "    'roc_auc': 'roc_auc',\n",
    "    'accuracy': 'accuracy',\n",
    "    'balanced_accuracy': 'balanced_accuracy'\n",
    "}\n",
    "\n",
    "# Perform cross-validation using the pipeline\n",
    "cv_results = cross_validate(model_pipeline, X, Y, cv=5, scoring=scoring, return_train_score=True)\n",
    "\n",
    "# Display the training and validation results\n",
    "print(\"Training results:\")\n",
    "print(f\"Mean Negative Log Loss: {cv_results['train_neg_log_loss'].mean():.4f}\")\n",
    "print(f\"Mean ROC AUC: {cv_results['train_roc_auc'].mean():.4f}\")\n",
    "print(f\"Mean Accuracy: {cv_results['train_accuracy'].mean():.4f}\")\n",
    "print(f\"Mean Balanced Accuracy: {cv_results['train_balanced_accuracy'].mean():.4f}\")\n",
    "\n",
    "print(\"\\nValidation results:\")\n",
    "print(f\"Mean Negative Log Loss: {cv_results['test_neg_log_loss'].mean():.4f}\")\n",
    "print(f\"Mean ROC AUC: {cv_results['test_roc_auc'].mean():.4f}\")\n",
    "print(f\"Mean Accuracy: {cv_results['test_accuracy'].mean():.4f}\")\n",
    "print(f\"Mean Balanced Accuracy: {cv_results['test_balanced_accuracy'].mean():.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Display the fold-level results as a pandas data frame and sorted by negative log loss of the test (validation) set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>test_neg_log_loss</th>\n",
       "      <th>test_roc_auc</th>\n",
       "      <th>test_accuracy</th>\n",
       "      <th>test_balanced_accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.413153</td>\n",
       "      <td>0.897008</td>\n",
       "      <td>0.851044</td>\n",
       "      <td>0.769948</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.367746</td>\n",
       "      <td>0.903050</td>\n",
       "      <td>0.854598</td>\n",
       "      <td>0.770004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.365701</td>\n",
       "      <td>0.907273</td>\n",
       "      <td>0.857033</td>\n",
       "      <td>0.780424</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.352683</td>\n",
       "      <td>0.906301</td>\n",
       "      <td>0.853655</td>\n",
       "      <td>0.778853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.349777</td>\n",
       "      <td>0.902032</td>\n",
       "      <td>0.857494</td>\n",
       "      <td>0.777244</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   test_neg_log_loss  test_roc_auc  test_accuracy  test_balanced_accuracy\n",
       "1          -0.413153      0.897008       0.851044                0.769948\n",
       "0          -0.367746      0.903050       0.854598                0.770004\n",
       "4          -0.365701      0.907273       0.857033                0.780424\n",
       "2          -0.352683      0.906301       0.853655                0.778853\n",
       "3          -0.349777      0.902032       0.857494                0.777244"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get fold-level results from cross-validation\n",
    "fold_results = pd.DataFrame(cv_results)\n",
    "\n",
    "# Sort the results by negative log loss of the test set (validation set)\n",
    "fold_results_sorted = fold_results.sort_values(by='test_neg_log_loss', ascending=True)\n",
    "\n",
    "# Display the sorted fold-level results\n",
    "fold_results_sorted[['test_neg_log_loss', 'test_roc_auc', 'test_accuracy', 'test_balanced_accuracy']]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate the mean of each metric. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_neg_log_loss        -0.369812\n",
      "test_roc_auc              0.903133\n",
      "test_accuracy             0.854765\n",
      "test_balanced_accuracy    0.775295\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Calculate the mean of each metric\n",
    "mean_metrics = fold_results[['test_neg_log_loss', 'test_roc_auc', 'test_accuracy', 'test_balanced_accuracy']].mean()\n",
    "\n",
    "# Display the mean values\n",
    "print(mean_metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate the same performance metrics (negative log loss, ROC AUC, accuracy, and balanced accuracy) using the testing data `X_test` and `Y_test`. Display results as a dictionary.\n",
    "\n",
    "*Tip*: both, `roc_auc()` and `neg_log_loss()` will require prediction scores from `pipe.predict_proba()`. However, for `roc_auc()` you should only pass the last column `Y_pred_proba[:, 1]`. Use `Y_pred_proba` with `neg_log_loss()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Negative Log Loss': 0.3807704552987868, 'ROC AUC': 0.9021627025187715, 'Accuracy': 0.8555635172484389, 'Balanced Accuracy': 0.776772504807004}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Make predictions on the test set\n",
    "Y_pred = model_pipeline.predict(X_test)  # Predicted labels\n",
    "Y_pred_proba = model_pipeline.predict_proba(X_test)  # Predicted probabilities\n",
    "\n",
    "# Calculate the performance metrics\n",
    "neg_log_loss_value = log_loss(Y_test, Y_pred_proba)  # Negative log loss\n",
    "roc_auc_value = roc_auc_score(Y_test, Y_pred_proba[:, 1])  # ROC AUC (for the positive class)\n",
    "accuracy_value = accuracy_score(Y_test, Y_pred)  # Accuracy\n",
    "balanced_accuracy_value = balanced_accuracy_score(Y_test, Y_pred)  # Balanced Accuracy\n",
    "\n",
    "# Store the results in a dictionary\n",
    "performance_metrics = {\n",
    "    \"Negative Log Loss\": neg_log_loss_value,\n",
    "    \"ROC AUC\": roc_auc_value,\n",
    "    \"Accuracy\": accuracy_value,\n",
    "    \"Balanced Accuracy\": balanced_accuracy_value\n",
    "}\n",
    "\n",
    "# Display the results\n",
    "print(performance_metrics)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Target Recoding\n",
    "\n",
    "In the first code chunk of this document, we loaded the data and immediately recoded the target variable `income`. Why is this [convenient](https://scikit-learn.org/stable/modules/model_evaluation.html#binary-case)?\n",
    "\n",
    "The specific line was:\n",
    "\n",
    "```\n",
    "adult_dt = (pd.read_csv('../05_src/data/adult/adult.data', header = None, names = columns)\n",
    "              .assign(income = lambda x: (x.income.str.strip() == '>50K')*1))\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is convenient because it transforms the target variable 'income' into a binary format, which is an essential preprocessing step for classification problems in machine learning. It creates a binary target for a binary classification, ensures compatibility sckit-learn, better model performance. For ROC AUC target label of interest should be encoded as 1 for the positive class. This is important because the AUC score is computed by plotting the true positive rate (sensitivity) against the false positive rate at various thresholds."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Criteria\n",
    "\n",
    "The [rubric](./assignment_2_rubric_clean.xlsx) contains the criteria for assessment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Submission Information\n",
    "\n",
    "ðŸš¨ **Please review our [Assignment Submission Guide](https://github.com/UofT-DSI/onboarding/blob/main/onboarding_documents/submissions.md)** ðŸš¨ for detailed instructions on how to format, branch, and submit your work. Following these guidelines is crucial for your submissions to be evaluated correctly.\n",
    "\n",
    "### Submission Parameters:\n",
    "* Submission Due Date: `HH:MM AM/PM - DD/MM/YYYY`\n",
    "* The branch name for your repo should be: `assignment-2`\n",
    "* What to submit for this assignment:\n",
    "    * This Jupyter Notebook (assignment_2.ipynb) should be populated and should be the only change in your pull request.\n",
    "* What the pull request link should look like for this assignment: `https://github.com/<your_github_username>/production/pull/<pr_id>`\n",
    "    * Open a private window in your browser. Copy and paste the link to your pull request into the address bar. Make sure you can see your pull request properly. This helps the technical facilitator and learning support staff review your submission easily.\n",
    "\n",
    "Checklist:\n",
    "- [ ] Created a branch with the correct naming convention.\n",
    "- [ ] Ensured that the repository is public.\n",
    "- [ ] Reviewed the PR description guidelines and adhered to them.\n",
    "- [ ] Verify that the link is accessible in a private browser window.\n",
    "\n",
    "If you encounter any difficulties or have questions, please don't hesitate to reach out to our team via our Slack at `#cohort-3-help`. Our Technical Facilitators and Learning Support staff are here to help you navigate any challenges."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reference\n",
    "\n",
    "Becker,Barry and Kohavi,Ronny. (1996). Adult. UCI Machine Learning Repository. https://doi.org/10.24432/C5XW20."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dsi_participant",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
